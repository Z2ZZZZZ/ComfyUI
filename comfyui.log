** ComfyUI startup time: 2024-02-24 12:34:42.548074
[2024-02-24 12:34] ** Platform: Windows
[2024-02-24 12:34] ** Python version: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
[2024-02-24 12:34] ** Python executable: C:\Users\zzzzz\AppData\Local\Programs\Python\Python311\python.exe
[2024-02-24 12:34] ** Log path: C:\Users\zzzzz\Documents\GitHub\ComfyUI\comfyui.log
[2024-02-24 12:34] 
Prestartup times for custom nodes:
[2024-02-24 12:34]    0.1 seconds: C:\Users\zzzzz\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-02-24 12:34] 
[2024-02-24 12:34] Total VRAM 8192 MB, total RAM 16089 MB
[2024-02-24 12:34] Forcing FP16.
[2024-02-24 12:34] Set vram state to: NORMAL_VRAM
[2024-02-24 12:34] Device: cuda:0 NVIDIA GeForce RTX 3070 Ti Laptop GPU : cudaMallocAsync
[2024-02-24 12:34] VAE dtype: torch.bfloat16
[2024-02-24 12:34] Using pytorch cross attention
[2024-02-24 12:34] ### Loading: ComfyUI-Manager (V2.7.2)
[2024-02-24 12:34] ### ComfyUI Revision: 2014 [1df07e35] | Released on '2024-02-24'
[2024-02-24 12:34] 
Import times for custom nodes:
[2024-02-24 12:34]    0.6 seconds: C:\Users\zzzzz\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-02-24 12:34] 
[2024-02-24 12:34] Starting server
[2024-02-24 12:34] 
[2024-02-24 12:34] To see the GUI go to: http://127.0.0.1:8188
[2024-02-24 12:34] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-02-24 12:34] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-02-24 12:34] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-02-24 12:34] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-02-24 12:35] FETCH DATA from: C:\Users\zzzzz\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager\extension-node-map.json
[2024-02-24 12:36] got prompt
[2024-02-24 12:36] model_type EPS
[2024-02-24 12:36] adm 2816
[2024-02-24 12:37] Using pytorch attention in VAE
[2024-02-24 12:37] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-02-24 12:37] Using pytorch attention in VAE
[2024-02-24 12:37] clip missing: ['clip_l.text_projection', 'clip_l.logit_scale']
[2024-02-24 12:37] clip unexpected: ['clip_l.transformer.text_model.embeddings.position_ids']
[2024-02-24 12:37] loaded straight to GPU
[2024-02-24 12:37] Requested to load SDXL
[2024-02-24 12:37] Loading 1 new model
[2024-02-24 12:37] Requested to load SDXLClipModel
[2024-02-24 12:37] Loading 1 new model
[2024-02-24 12:37] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:37] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:37] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
C:\Users\zzzzz\Documents\GitHub\ComfyUI\comfy\ldm\modules\attention.py:344: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:308.)
  out = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=0.0, is_causal=False)
[2024-02-24 12:37] Requested to load SDXL
[2024-02-24 12:37] Loading 1 new model
[2024-02-24 12:37] 100%|███████████████| 20/20 [00:04<00:00,  7.03it/s]100%|███████████████| 20/20 [00:04<00:00,  4.37it/s]
[2024-02-24 12:37] Requested to load AutoencoderKL
[2024-02-24 12:37] Loading 1 new model
[2024-02-24 12:37] Prompt executed in 43.44 seconds
[2024-02-24 12:38] got prompt
[2024-02-24 12:38] model_type EPS
[2024-02-24 12:38] adm 2816
[2024-02-24 12:38] Using pytorch attention in VAE
[2024-02-24 12:38] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-02-24 12:38] Using pytorch attention in VAE
[2024-02-24 12:38] clip missing: ['clip_l.text_projection', 'clip_l.logit_scale']
[2024-02-24 12:38] clip unexpected: ['clip_l.transformer.text_model.embeddings.position_ids']
[2024-02-24 12:38] loaded straight to GPU
[2024-02-24 12:38] Requested to load SDXL
[2024-02-24 12:38] Loading 1 new model
[2024-02-24 12:38] Requested to load SDXLClipModel
[2024-02-24 12:38] Loading 1 new model
[2024-02-24 12:38] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:38] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:38] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:38] Requested to load SDXL
[2024-02-24 12:38] Loading 1 new model
[2024-02-24 12:38] 100%|███████████████| 20/20 [00:02<00:00,  6.96it/s]100%|███████████████| 20/20 [00:02<00:00,  7.08it/s]
[2024-02-24 12:38] Requested to load AutoencoderKL
[2024-02-24 12:38] Loading 1 new model
[2024-02-24 12:38] Prompt executed in 24.82 seconds
[2024-02-24 12:40] got prompt
[2024-02-24 12:40] 100%|███████████████| 20/20 [00:05<00:00,  3.82it/s]100%|███████████████| 20/20 [00:05<00:00,  3.35it/s]
[2024-02-24 12:40] Prompt executed in 6.14 seconds
[2024-02-24 12:41] got prompt
[2024-02-24 12:41] 100%|███████████████| 20/20 [00:20<00:00,  1.05it/s]100%|███████████████| 20/20 [00:20<00:00,  1.02s/it]
[2024-02-24 12:41] Prompt executed in 22.64 seconds
[2024-02-24 12:42] got prompt
[2024-02-24 12:42] model_type EPS
[2024-02-24 12:42] adm 2816
[2024-02-24 12:42] Using pytorch attention in VAE
[2024-02-24 12:42] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-02-24 12:42] Using pytorch attention in VAE
[2024-02-24 12:42] clip missing: ['clip_l.text_projection', 'clip_l.logit_scale']
[2024-02-24 12:42] left over keys: dict_keys(['denoiser.sigmas'])
[2024-02-24 12:42] loaded straight to GPU
[2024-02-24 12:42] Requested to load SDXL
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:42] Requested to load SDXLClipModel
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:42] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:42] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:42] WARNING: shape mismatch when trying to apply embedding, embedding will be ignored 768 1280
[2024-02-24 12:42] Requested to load SDXL
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:42] 100%|█████████████████| 7/7 [00:06<00:00,  1.08it/s]100%|█████████████████| 7/7 [00:06<00:00,  1.04it/s]
[2024-02-24 12:42] Requested to load AutoencoderKL
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:42] Prompt executed in 27.97 seconds
[2024-02-24 12:42] got prompt
[2024-02-24 12:42] Requested to load SDXL
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:42] 100%|█████████████████| 1/1 [00:00<00:00,  1.92it/s]100%|█████████████████| 1/1 [00:00<00:00,  1.92it/s]
[2024-02-24 12:42] Requested to load AutoencoderKL
[2024-02-24 12:42] Loading 1 new model
[2024-02-24 12:43] Prompt executed in 3.22 seconds
